{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 4966565,
          "sourceType": "datasetVersion",
          "datasetId": 2880535
        },
        {
          "sourceId": 7832583,
          "sourceType": "datasetVersion",
          "datasetId": 4590606
        },
        {
          "sourceId": 4298,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 3093
        }
      ],
      "dockerImageVersionId": 30559,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Employed the Llama2-7b parameter model, RAG framework, Langchain, and Chroma Vector Database to intelligently query the freely available PDF version of \"Feynman Lectures on Computation\" converted into a text format.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "id": "2FI_zoCKulqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensuring the dependencies are working\n",
        "\n",
        "!pip install transformers==4.33.0 accelerate==0.22.0 einops==0.6.1 langchain==0.0.300 xformers==0.0.21 \\\n",
        "bitsandbytes==0.41.1 sentence_transformers==2.2.2 chromadb==0.4.12"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T10:52:47.319563Z",
          "iopub.execute_input": "2024-03-13T10:52:47.320213Z",
          "iopub.status.idle": "2024-03-13T11:08:10.414666Z",
          "shell.execute_reply.started": "2024-03-13T10:52:47.320178Z",
          "shell.execute_reply": "2024-03-13T11:08:10.413343Z"
        },
        "trusted": true,
        "id": "SVpxSbBMulqt",
        "outputId": "aff63fec-84f2-43e7-dc97-deaaa645bac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers==4.33.0 in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: accelerate==0.22.0 in /opt/conda/lib/python3.10/site-packages (0.22.0)\nCollecting einops==0.6.1\n  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m694.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting langchain==0.0.300\n  Downloading langchain-0.0.300-py3-none-any.whl (1.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hCollecting xformers==0.0.21\n  Downloading xformers-0.0.21-cp310-cp310-manylinux2014_x86_64.whl (167.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.0/167.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting bitsandbytes==0.41.1\n  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting sentence_transformers==2.2.2\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting chromadb==0.4.12\n  Downloading chromadb-0.4.12-py3-none-any.whl (426 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.5/426.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.0) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.22.0) (2.0.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (2.0.17)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (3.8.4)\nRequirement already satisfied: anyio<4.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (3.7.0)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (4.0.2)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (0.6.0)\nCollecting jsonpatch<2.0,>=1.33 (from langchain==0.0.300)\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nCollecting langsmith<0.1.0,>=0.0.38 (from langchain==0.0.300)\n  Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (2.8.5)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (1.10.9)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.300) (8.2.2)\nCollecting torch>=1.10.0 (from accelerate==0.22.0)\n  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.15.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.11.2)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.1.99)\nCollecting chroma-hnswlib==0.7.3 (from chromadb==0.4.12)\n  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hRequirement already satisfied: fastapi<0.100.0,>=0.95.2 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (0.98.0)\nRequirement already satisfied: uvicorn[standard]>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (0.22.0)\nCollecting posthog>=2.4.0 (from chromadb==0.4.12)\n  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m125.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (4.6.3)\nCollecting pulsar-client>=3.1.0 (from chromadb==0.4.12)\n  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb==0.4.12)\n  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting pypika>=0.48.9 (from chromadb==0.4.12)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting overrides>=7.3.1 (from chromadb==0.4.12)\n  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (5.12.0)\nCollecting bcrypt>=4.0.1 (from chromadb==0.4.12)\n  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.12) (0.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.22.0) (3.1.2)\nCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting triton==2.0.0 (from torch>=1.10.0->accelerate==0.22.0)\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.22.0) (68.0.0)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate==0.22.0) (0.40.0)\nCollecting cmake (from triton==2.0.0->torch>=1.10.0->accelerate==0.22.0)\n  Downloading cmake-3.28.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting lit (from triton==2.0.0->torch>=1.10.0->accelerate==0.22.0)\n  Downloading lit-18.1.1.tar.gz (161 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.300) (1.3.1)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (3.4)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.300) (1.1.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (3.20.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (0.9.0)\nRequirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi<0.100.0,>=0.95.2->chromadb==0.4.12) (0.27.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.0) (2023.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.300) (2.0)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.4.12)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.12) (23.5.26)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.12) (3.20.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.33.0) (3.0.9)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (1.16.0)\nCollecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.4.12)\n  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nRequirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (2.2.1)\nRequirement already satisfied: python-dateutil>2.1 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb==0.4.12) (2.8.2)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from pulsar-client>=3.1.0->chromadb==0.4.12) (2023.7.22)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.0) (1.26.15)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.300) (2.0.2)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb==0.4.12) (8.1.7)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.14.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.6.0)\nRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (1.0.0)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.17.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (0.20.0)\nRequirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.12) (11.0.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers==2.2.2) (9.5.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.300) (1.0.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.12)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.22.0) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.22.0) (1.3.0)\nBuilding wheels for collected packages: sentence_transformers, pypika, lit\n  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=5040e7464dd672d3abb1a3839e1f008ba3096e0b72bad25c0b9cb7f4aa8d4b42\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=341fbdb226970e588c1427fd43c00619dd864329b65fc91c334ac6779e205061\n  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for lit: filename=lit-18.1.1-py3-none-any.whl size=96363 sha256=25582f47ad5413eecf8bf84370478c7c961d974de9396c3e324e84b27f8c93e1\n  Stored in directory: /root/.cache/pip/wheels/1d/74/6b/88e95944e9f9078f1dc1c0f634a542efb4d26ecae6000ca8cf\nSuccessfully built sentence_transformers pypika lit\nInstalling collected packages: pypika, monotonic, lit, cmake, bitsandbytes, pulsar-client, overrides, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, jsonpatch, humanfriendly, einops, chroma-hnswlib, bcrypt, posthog, nvidia-cusolver-cu11, nvidia-cudnn-cu11, langsmith, coloredlogs, onnxruntime, langchain, chromadb, triton, torch, xformers, sentence_transformers\n  Attempting uninstall: overrides\n    Found existing installation: overrides 6.5.0\n    Uninstalling overrides-6.5.0:\n      Successfully uninstalled overrides-6.5.0\n  Attempting uninstall: jsonpatch\n    Found existing installation: jsonpatch 1.32\n    Uninstalling jsonpatch-1.32:\n      Successfully uninstalled jsonpatch-1.32\n  Attempting uninstall: torch\n    Found existing installation: torch 2.0.0\n    Uninstalling torch-2.0.0:\n      Successfully uninstalled torch-2.0.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-pubsublite 1.8.2 requires overrides<7.0.0,>=6.0.1, but you have overrides 7.7.0 which is incompatible.\njupyterlab-lsp 4.2.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\ntorchdata 0.6.0 requires torch==2.0.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bcrypt-4.1.2 bitsandbytes-0.41.1 chroma-hnswlib-0.7.3 chromadb-0.4.12 cmake-3.28.3 coloredlogs-15.0.1 einops-0.6.1 humanfriendly-10.0 jsonpatch-1.33 langchain-0.0.300 langsmith-0.0.92 lit-18.1.1 monotonic-1.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 onnxruntime-1.17.1 overrides-7.3.1 posthog-3.5.0 pulsar-client-3.4.0 pypika-0.48.9 sentence_transformers-2.2.2 torch-2.0.1 triton-2.0.0 xformers-0.0.21\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic import\n",
        "\n",
        "from torch import cuda, bfloat16\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from time import time\n",
        "#import chromadb\n",
        "#from chromadb.config import Settings\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import Chroma\n"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T11:08:10.416853Z",
          "iopub.execute_input": "2024-03-13T11:08:10.417143Z",
          "iopub.status.idle": "2024-03-13T11:08:19.695353Z",
          "shell.execute_reply.started": "2024-03-13T11:08:10.417112Z",
          "shell.execute_reply": "2024-03-13T11:08:19.694539Z"
        },
        "trusted": true,
        "id": "wK8X4PaVulqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize model, tokenizer, query pipeline"
      ],
      "metadata": {
        "id": "vsyNLuWAulqu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the model, the device, and the `bitsandbytes` configuration."
      ],
      "metadata": {
        "id": "Hx2DVEZpulqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the Llama2-7b parameter model using 4-bit Quantization\n",
        "\n",
        "model_id = '/kaggle/input/llama-2/pytorch/7b-chat-hf/1'\n",
        "\n",
        "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# set quantization configuration to load large model with less GPU memory\n",
        "# this requires the `bitsandbytes` library\n",
        "\n",
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=bfloat16\n",
        ")"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T11:08:19.696512Z",
          "iopub.execute_input": "2024-03-13T11:08:19.696995Z",
          "iopub.status.idle": "2024-03-13T11:08:19.786307Z",
          "shell.execute_reply.started": "2024-03-13T11:08:19.696967Z",
          "shell.execute_reply": "2024-03-13T11:08:19.785506Z"
        },
        "trusted": true,
        "id": "TlxN03z2ulqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the model and the tokenizer."
      ],
      "metadata": {
        "id": "-lCNkvZdulqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the model and tokenizer\n",
        "\n",
        "time_1 = time()\n",
        "model_config = transformers.AutoConfig.from_pretrained(\n",
        "    model_id,\n",
        ")\n",
        "\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    config=model_config,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map='auto',\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "time_2 = time()\n",
        "print(f\"Prepare model, tokenizer: {round(time_2-time_1, 3)} sec.\")"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T11:08:19.788933Z",
          "iopub.execute_input": "2024-03-13T11:08:19.789619Z",
          "iopub.status.idle": "2024-03-13T11:12:27.746318Z",
          "shell.execute_reply.started": "2024-03-13T11:08:19.789582Z",
          "shell.execute_reply": "2024-03-13T11:12:27.745454Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "1c1985368f454ce3a3a2f581eb234e3d"
          ]
        },
        "id": "VUPnZsBRulqv",
        "outputId": "2dc56e66-6b26-4453-9254-68d95630a09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c1985368f454ce3a3a2f581eb234e3d"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Prepare model, tokenizer: 247.951 sec.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the query pipeline"
      ],
      "metadata": {
        "id": "PLIk6tCaulqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "time_1 = time()\n",
        "\n",
        "query_pipeline = transformers.pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        torch_dtype=torch.float16,\n",
        "        device_map=\"auto\",)\n",
        "\n",
        "time_2 = time()\n",
        "\n",
        "print(f\"Prepare pipeline: {round(time_2-time_1, 3)} sec.\")"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T11:12:27.747434Z",
          "iopub.execute_input": "2024-03-13T11:12:27.747740Z",
          "iopub.status.idle": "2024-03-13T11:12:30.347778Z",
          "shell.execute_reply.started": "2024-03-13T11:12:27.747715Z",
          "shell.execute_reply": "2024-03-13T11:12:30.346737Z"
        },
        "trusted": true,
        "id": "brYgCJAgulqv",
        "outputId": "bd50c805-64aa-4c17-b896-b693fb86f4ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Prepare pipeline: 2.595 sec.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a function for testing the pipeline."
      ],
      "metadata": {
        "id": "vkmuuy9aulqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(tokenizer, pipeline, prompt_to_test):\n",
        "    \"\"\"\n",
        "    Perform a query\n",
        "    print the result\n",
        "    Args:\n",
        "        tokenizer: the tokenizer\n",
        "        pipeline: the pipeline\n",
        "        prompt_to_test: the prompt\n",
        "    Returns\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    # adapted from https://huggingface.co/blog/llama2#using-transformers\n",
        "\n",
        "    time_1 = time()\n",
        "    sequences = pipeline(\n",
        "        prompt_to_test,\n",
        "        do_sample=True,\n",
        "        top_k=10,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        max_length=200,)\n",
        "    time_2 = time()\n",
        "    print(f\"Test inference: {round(time_2-time_1, 3)} sec.\")\n",
        "    for seq in sequences:\n",
        "        print(f\"Result: {seq['generated_text']}\")"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T11:12:30.349121Z",
          "iopub.execute_input": "2024-03-13T11:12:30.349504Z",
          "iopub.status.idle": "2024-03-13T11:12:30.356671Z",
          "shell.execute_reply.started": "2024-03-13T11:12:30.349466Z",
          "shell.execute_reply": "2024-03-13T11:12:30.355629Z"
        },
        "trusted": true,
        "id": "Uz71i-Wdulqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the query pipeline\n",
        "\n",
        "We test the pipeline with a query about the meaning of Computation."
      ],
      "metadata": {
        "id": "YvQkdsyTulqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(tokenizer,\n",
        "           query_pipeline,\n",
        "           \"Please explain what is Computation?\")"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T11:12:30.358158Z",
          "iopub.execute_input": "2024-03-13T11:12:30.358541Z",
          "iopub.status.idle": "2024-03-13T11:12:52.142329Z",
          "shell.execute_reply.started": "2024-03-13T11:12:30.358505Z",
          "shell.execute_reply": "2024-03-13T11:12:52.141361Z"
        },
        "trusted": true,
        "id": "-5yl10R9ulqw",
        "outputId": "68d9c7af-1121-4c0a-e324-1687c2cb6cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Test inference: 21.763 sec.\nResult: Please explain what is Computation? Composition is a fundamental concept in computer science that refers to the process of combining two or more things (such as programs, data, or functions) to create a new entity. nobody@example.com (John Doe) wrote: Hello, I'm interested in learning more about computation. In general, computation refers to any process of combining or manipulating data in a systematic and algorithmic way. Computation involves the use of algorithms, which are well-defined procedures for solving mathematical problems or performing tasks. In computer science, the term computation often refers specifically to the processes that are performed by a computer, such as executing programs or manipulating data in a computer program. The concept of computation is central to many areas of computer science, including algorithms, programming language, computer architecture, and database systems. In computational complexity theory, the concept of computation is often used to study the resources (such as time or space) required to perform a computational task\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking the model with a HuggingFace pipeline\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-09-23T19:22:16.433666Z",
          "iopub.execute_input": "2023-09-23T19:22:16.434937Z",
          "iopub.status.idle": "2023-09-23T19:22:16.440864Z",
          "shell.execute_reply.started": "2023-09-23T19:22:16.434891Z",
          "shell.execute_reply": "2023-09-23T19:22:16.439217Z"
        },
        "id": "EqaYryEiulqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(pipeline=query_pipeline)\n",
        "# checking again that everything is working fine\n",
        "llm(prompt=\"Please explain what is Computation very briefly and tell us what is the connection of computation and thermodynamics, In less than 100 words.\")"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T11:12:52.143664Z",
          "iopub.execute_input": "2024-03-13T11:12:52.143997Z",
          "iopub.status.idle": "2024-03-13T11:13:14.785776Z",
          "shell.execute_reply.started": "2024-03-13T11:12:52.143969Z",
          "shell.execute_reply": "2024-03-13T11:13:14.784744Z"
        },
        "trusted": true,
        "id": "ON4kdwN8ulqx",
        "outputId": "d535df8c-8620-47ee-e4c2-463806fe4512"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "' Unterscheidung between computation and information processing. Computation is a fundamental concept in computer science that refers to the process of manipulating and transforming data in a systematic and algorithmic way. It involves the use of computational models, such as Turing machines, to perform tasks such as problem solving, data analysis, and decision making. The connection between computation and thermodynamics is that both are concerned with the flow of information and energy. In thermodynamics, the flow of energy is studied in terms of its entropy, which is a measure of the amount of disorder or randomness in a system. Similarly, in computation, the flow of information is studied in terms of the complexity of the computational model, which can be thought of as a measure of the disorder or randomness of the system.\\n\\nIn summary, computation is the process of manipulating and transforming data in a systematic and algorithmic way, while thermodynamics is the study of the flow of energy and its associated entropy. Both are concerned with the flow of information and energy, and the connection between the two is that the complexity of a computational model can be thought of as a measure of the disorder or randomness of a system, much like the entropy of a thermodynamic system.'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using our data"
      ],
      "metadata": {
        "id": "3fBZaM2Culqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = TextLoader(\"/kaggle/input/feynmancomputation/feynman_computation.txt\",\n",
        "                    encoding=\"utf8\")\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T11:13:14.787093Z",
          "iopub.execute_input": "2024-03-13T11:13:14.787388Z",
          "iopub.status.idle": "2024-03-13T11:13:14.807479Z",
          "shell.execute_reply.started": "2024-03-13T11:13:14.787362Z",
          "shell.execute_reply": "2024-03-13T11:13:14.806577Z"
        },
        "trusted": true,
        "id": "R-2bzdz0ulqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data in chunks\n",
        "\n",
        "We split data in chunks using a recursive character text splitter."
      ],
      "metadata": {
        "id": "63zZHAXAulqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "all_splits = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T11:13:14.811865Z",
          "iopub.execute_input": "2024-03-13T11:13:14.812175Z",
          "iopub.status.idle": "2024-03-13T11:13:14.862192Z",
          "shell.execute_reply.started": "2024-03-13T11:13:14.812148Z",
          "shell.execute_reply": "2024-03-13T11:13:14.861125Z"
        },
        "trusted": true,
        "id": "4Rf2_poTulqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Embeddings and Storing in Vector Store"
      ],
      "metadata": {
        "id": "u34ZZCUJulqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the embeddings using Sentence Transformer and HuggingFace embeddings."
      ],
      "metadata": {
        "id": "WEBGwls1ulqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "model_kwargs = {\"device\": \"cuda\"}\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T11:13:14.863591Z",
          "iopub.execute_input": "2024-03-13T11:13:14.863952Z",
          "iopub.status.idle": "2024-03-13T11:13:22.039368Z",
          "shell.execute_reply.started": "2024-03-13T11:13:14.863924Z",
          "shell.execute_reply": "2024-03-13T11:13:22.038495Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "b2e8551933d449f59757caf9e3af7297",
            "3ee5041162bc411291521825d0438a5f",
            "2a05522bc4eb4d7f9e63e36d07ad2ed6",
            "029cedcd2631470f8e3e51422f7e46f8",
            "3f234a34878c46f98e0aa26fe920a920",
            "b9cd1188187a412cb3f8b974117843c0",
            "5565a3150c0c46129e6e65bf661f790b",
            "44a58f7baab943b7bd5ec0c8a716657b",
            "c3688852cf94494c963cf3693d73d0eb",
            "4ead09449031448f889c82ca759a9c4d",
            "469bbe8f7b4849ecb5c5eee55608e7a0",
            "02449e03c3254a8abba8cf5e8d1f0534",
            "a583782464474fca9eb6ac61f9aa6935",
            "c3bb5629d6f64ac1b949c332b2cbdade"
          ]
        },
        "id": "IkElyv65ulqz",
        "outputId": "f0543321-7e52-41ae-8830-cb82fd803401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading .gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2e8551933d449f59757caf9e3af7297"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading 1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ee5041162bc411291521825d0438a5f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a05522bc4eb4d7f9e63e36d07ad2ed6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "029cedcd2631470f8e3e51422f7e46f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f234a34878c46f98e0aa26fe920a920"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9cd1188187a412cb3f8b974117843c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5565a3150c0c46129e6e65bf661f790b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44a58f7baab943b7bd5ec0c8a716657b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3688852cf94494c963cf3693d73d0eb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ead09449031448f889c82ca759a9c4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "469bbe8f7b4849ecb5c5eee55608e7a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02449e03c3254a8abba8cf5e8d1f0534"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a583782464474fca9eb6ac61f9aa6935"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3bb5629d6f64ac1b949c332b2cbdade"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize ChromaDB with the document splits, the embeddings defined previously and with the option to persist it locally."
      ],
      "metadata": {
        "id": "sUP10gpGulqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma.from_documents(documents=all_splits, embedding=embeddings, persist_directory=\"chroma_db\")"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T11:13:22.040451Z",
          "iopub.execute_input": "2024-03-13T11:13:22.040768Z",
          "iopub.status.idle": "2024-03-13T11:13:34.682001Z",
          "shell.execute_reply.started": "2024-03-13T11:13:22.040737Z",
          "shell.execute_reply": "2024-03-13T11:13:34.680886Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "6406d111a89d4058bd8f76427daeb71e"
          ]
        },
        "id": "9YFQY160ulqz",
        "outputId": "6080d79f-6e8c-429e-bf5b-b2c4cabe30a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/28 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6406d111a89d4058bd8f76427daeb71e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize chain"
      ],
      "metadata": {
        "id": "LnnbQq7Mulqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever()\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T11:13:34.683386Z",
          "iopub.execute_input": "2024-03-13T11:13:34.683733Z",
          "iopub.status.idle": "2024-03-13T11:13:34.689567Z",
          "shell.execute_reply.started": "2024-03-13T11:13:34.683672Z",
          "shell.execute_reply": "2024-03-13T11:13:34.688625Z"
        },
        "trusted": true,
        "id": "wMa7mhGIulqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the Retrieval-Augmented Generation\n",
        "\n",
        "\n",
        "We define a test function, that will run the query and time it."
      ],
      "metadata": {
        "id": "aUcSNPDDulqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_rag(qa, query):\n",
        "    print(f\"Query: {query}\\n\")\n",
        "    time_1 = time()\n",
        "    result = qa.run(query)\n",
        "    time_2 = time()\n",
        "    print(f\"Inference time: {round(time_2-time_1, 3)} sec.\")\n",
        "    print(\"\\nResult: \", result)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T11:13:34.691132Z",
          "iopub.execute_input": "2024-03-13T11:13:34.691482Z",
          "iopub.status.idle": "2024-03-13T11:13:34.718191Z",
          "shell.execute_reply.started": "2024-03-13T11:13:34.691450Z",
          "shell.execute_reply": "2024-03-13T11:13:34.717346Z"
        },
        "trusted": true,
        "id": "goJXxcljulqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check few queries."
      ],
      "metadata": {
        "id": "ma9kXYROulq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Please explain what is Computation very briefly and tell us what is the connection of computation and thermodynamics.\"\n",
        "test_rag(qa, query)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T11:13:34.719449Z",
          "iopub.execute_input": "2024-03-13T11:13:34.719720Z",
          "iopub.status.idle": "2024-03-13T11:13:44.676198Z",
          "shell.execute_reply.started": "2024-03-13T11:13:34.719674Z",
          "shell.execute_reply": "2024-03-13T11:13:44.675243Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "13e9f9539f6a44e6886a7386cb0f91b4"
          ]
        },
        "id": "lYjihOZ2ulq0",
        "outputId": "702ae8bb-bc35-4893-f1b5-0148d0fa6b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Query: Please explain what is Computation very briefly and tell us what is the connection of computation and thermodynamics.\n\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13e9f9539f6a44e6886a7386cb0f91b4"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n\u001b[1m> Finished chain.\u001b[0m\nInference time: 9.945 sec.\n\nResult:   Computation is the process of manipulating information, typically using a computer. Thermodynamics is the study of the relationships between heat, work, and energy. The connection between computation and thermodynamics is that the energy required to perform computations can be measured and analyzed using thermodynamic concepts, such as entropy. For example, the entropy of a computation can be used to quantify the amount of information that is processed during the computation.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is a Turing Machine, How is it related to the Halting problem?\"\n",
        "test_rag(qa, query)"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T11:13:44.677446Z",
          "iopub.execute_input": "2024-03-13T11:13:44.677836Z",
          "iopub.status.idle": "2024-03-13T11:14:55.803655Z",
          "shell.execute_reply.started": "2024-03-13T11:13:44.677798Z",
          "shell.execute_reply": "2024-03-13T11:14:55.802743Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "5397dbc053af4d8a965edfbef1999c53"
          ]
        },
        "id": "5-gjZcxAulq0",
        "outputId": "fbdae1d5-1e1a-48e7-ff8f-62d201b598fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Query: What is a Turing Machine, How is it related to the Halting problem?\n\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5397dbc053af4d8a965edfbef1999c53"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n\u001b[1m> Finished chain.\u001b[0m\nInference time: 71.122 sec.\n\nResult:   A Turing Machine is a mathematical model for computation that was first introduced by Alan Turing in the 1930s. It consists of a tape that can be read and written to, and a read/write head that can move along the tape. The machine can be in one of a finite number of states, and it can change state based on the input it reads and the tape it is currently reading. The Halting problem is a famous result in the theory of computation that states that there cannot exist an algorithm that can determine, given a particular Turing Machine and input, whether the machine will halt or run indefinitely. This result has important implications for the design and analysis of Turing Machines, and it highlights the fundamental limits of what can be computed using these machines.\n\nIn this answer, we will explore the concept of a Turing Machine, how it is related to the Halting problem, and the implications of this result for the field of computer science.\n\nWhat is a Turing Machine?\n\nA Turing Machine is a mathematical model for computation that was first introduced by Alan Turing in the 1930s. It consists of a tape that can be read and written to, and a read/write head that can move along the tape. The machine can be in one of a finite number of states, and it can change state based on the input it reads and the tape it is currently reading. The Turing Machine is a fundamental building block of the theory of computation, and it has been used to study the limits of computation and the nature of computation itself.\n\nHow is a Turing Machine related to the Halting problem?\n\nThe Halting problem is a famous result in the theory of computation that states that there cannot exist an algorithm that can determine, given a particular Turing Machine and input, whether the machine will halt or run indefinitely. This result has important implications for the design and analysis of Turing Machines, and it highlights the fundamental limits of what can be computed using these machines. The Halting problem is closely related to the concept of a Turing Machine, and it is often used as a tool for studying the properties of Turing Machines and their limitations.\n\nWhat are the implications of the Halting problem for the field of computer science?\n\nThe Halting problem has important implications for the field of computer science, as it highlights the fundamental limits of what can be computed using Turing Machines. It shows that there are certain problems that cannot be solved using these machines, and it provides a theoretical foundation for the design and analysis of algorithms and computational systems. The Halting problem also has practical implications for the design of computer systems, as it suggests that certain types of computations may be impossible or impractical to perform using current technology.\n\nIn conclusion, a Turing Machine is a mathematical model for computation that was first introduced by Alan Turing in the 1930s. It consists of a tape that can be read and written to, and a read/write head that can move along the tape. The Halting problem is a famous result in the theory of computation that states that there cannot exist an algorithm that can determine, given a particular Turing Machine and input, whether the machine will halt or run indefinitely. This result has important implications for the design and analysis of Turing Machines, and it highlights the fundamental limits of what can be computed using these machines.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document sources\n",
        "\n",
        "Let's check the documents sources, for the last query run."
      ],
      "metadata": {
        "id": "MQhQXMmeulq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs = vectordb.similarity_search(query)\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"Retrieved documents: {len(docs)}\")\n",
        "for doc in docs:\n",
        "    doc_details = doc.to_json()['kwargs']\n",
        "    print(\"Source: \", doc_details['metadata']['source'])\n",
        "    print(\"Text: \", doc_details['page_content'], \"\\n\")\n",
        "    break"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-03-13T11:14:55.804946Z",
          "iopub.execute_input": "2024-03-13T11:14:55.805243Z",
          "iopub.status.idle": "2024-03-13T11:14:55.850564Z",
          "shell.execute_reply.started": "2024-03-13T11:14:55.805215Z",
          "shell.execute_reply": "2024-03-13T11:14:55.849764Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "d7972061cf41477eb4e2ff91e14c22a9"
          ]
        },
        "id": "aTaWmf9Hulq0",
        "outputId": "abe9499c-caef-4332-c286-231f98dcbc8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Batches:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7972061cf41477eb4e2ff91e14c22a9"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Query: What is a Turing Machine, How is it related to the Halting problem?\nRetrieved documents: 4\nSource:  /kaggle/input/feynmancomputation/feynman_computation.txt\nText:  mathematician has a long strip of paper broken up into squares, in each of\nwhich he can write and read, one at a time. He looks at a square, and what he\nsees puts him in some state of mind which determines what he writes in the next\nsquare. So imagine the guy's brain having lots of different possible states which\nare mixed up and changed by looking at the strip of paper. After thinking along\nthese lines and abstracting a bit, Turing came up with a kind of machine which\nis referred to as - surprise, surprise - a Turing machine. We will see that these\nmachines are horribly inefficient and slow - so much so that no one would ever\nwaste their time building one except for amusement - but that, if we are patient\nwith them, they can do wonderful things.\nNow Turing invented all manner of Turing machines, but he eventually\ndiscovered one - the so-called Universal Turing Machine (UTM) - which was\nthe best of the bunch. Anything that any specific, special-purpose Turing \n\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}