# Intelligent Querying with Llama2-7b, RAG Framework, Langchain, and Chroma Vector Database

This project employs a combination of cutting-edge technologies including the Llama2-7b parameter model, RAG (Retriever-Answerer-Generator) framework, Langchain, and Chroma Vector Database to intelligently query the freely available PDF version of "Feynman Lectures on Computation" converted into a text format.

## Technologies Used

- **Llama2-7b Parameter Model**: Utilized for language understanding and generation tasks, providing a robust foundation for processing textual data.
- **RAG Framework**: Incorporates retriever, answerer, and generator components for comprehensive question answering and information retrieval capabilities.
- **Langchain**: Facilitates seamless integration and interoperability between various language models and frameworks, enhancing the overall efficiency and effectiveness of the system.
- **Chroma Vector Database**: Employs advanced indexing and similarity search techniques based on chroma vectors, enabling efficient querying and retrieval of relevant information.

## Key Features

- **Intelligent Querying**: The system intelligently processes queries to extract relevant information from the "Feynman Lectures on Computation" text corpus.
- **Natural Language Understanding**: Leveraging state-of-the-art language models for accurate comprehension of user queries and textual data.
- **Dynamic Retrieval**: The retriever component dynamically fetches relevant passages from the text corpus based on the input query.
- **Contextual Answer Generation**: Answers are generated in context, ensuring coherence and relevance to the user query.

